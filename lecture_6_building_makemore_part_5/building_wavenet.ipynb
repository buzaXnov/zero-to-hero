{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"names.txt\", \"r\") as file:\n",
    "    words = file.read().splitlines()\n",
    "\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build a vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {s: i+1 for i, s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 8  # context length: how many characters do we take to predict the next one\n",
    "def build_dataset(words):\n",
    "\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "\n",
    "        context = [0] * block_size\n",
    "        for ch in w + \".\":\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]    # crop and append\n",
    "\n",
    "    # basically we have a rolling window for context\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> y\n",
      ".......y --> u\n",
      "......yu --> h\n",
      ".....yuh --> e\n",
      "....yuhe --> n\n",
      "...yuhen --> g\n",
      "..yuheng --> .\n",
      "........ --> d\n",
      ".......d --> i\n",
      "......di --> o\n",
      ".....dio --> n\n",
      "....dion --> d\n",
      "...diond --> r\n",
      "..diondr --> e\n",
      ".diondre --> .\n",
      "........ --> x\n",
      ".......x --> a\n",
      "......xa --> v\n",
      ".....xav --> i\n",
      "....xavi --> e\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(Xtr[:20], Ytr[:20]):\n",
    "    print(f\"{''.join(itos[ix.item()] for ix in x)} --> {itos[y.item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "\n",
    "class Layer(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, x: torch.tensor) -> torch.tensor:\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def parameters() -> List[torch.tensor]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        bias: bool = True,\n",
    "        device: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        self.weights = torch.randn((in_features, out_features)) / in_features ** 0.5    # NOTE: kaiming init\n",
    "        self.bias = torch.zeros(out_features) if bias else None\n",
    "\n",
    "    def __call__(self, x: torch.tensor) -> torch.tensor:\n",
    "\n",
    "        self.out = x @ self.weights\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self) -> List[torch.tensor]:\n",
    "        return [self.weights] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        eps: float = 1e-5,\n",
    "        momentum: float = 0.1,\n",
    "    ) -> None:\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters\n",
    "        self.gamma = torch.ones(num_features)\n",
    "        self.beta = torch.zeros(num_features)\n",
    "        # buffers (trained with a running 'momentum update')\n",
    "        self.running_mean = torch.zeros(num_features)\n",
    "        self.running_var = torch.ones(num_features)\n",
    "\n",
    "    def __call__(self, x: torch.tensor) -> torch.tensor:\n",
    "        # calculate the forward pass\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                dim = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "\n",
    "            xmean = x.mean(dim, keepdim=True)\n",
    "            xvar = x.var(dim, keepdim=True)\n",
    "        else:  # inference\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = xhat * self.gamma + self.beta\n",
    "\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                # updated using the exponential moving average\n",
    "                self.running_mean = (\n",
    "                    1 - self.momentum\n",
    "                ) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (\n",
    "                    1 - self.momentum\n",
    "                ) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self) -> List[torch.tensor]:\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "class Tanh(Layer):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, x: torch.tensor) -> torch.tensor:\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self) -> Optional[List]:\n",
    "        return []\n",
    "\n",
    "\n",
    "# same name in torch.nn\n",
    "class Embedding(Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim) -> None:\n",
    "        self.weights = torch.randn((num_embeddings, embedding_dim))\n",
    "\n",
    "    def __call__(self, IX: torch.tensor) -> torch.tensor:\n",
    "        self.out = self.weights[IX]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self) -> List:\n",
    "        return [self.weights]\n",
    "\n",
    "\n",
    "class FlattenConsecutive(Layer):\n",
    "    def __init__(self, n: int) -> None:\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x: torch.tensor) -> torch.tensor:\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n, C*self.n)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self) -> List:\n",
    "        return []\n",
    "\n",
    "\n",
    "class Sequential(Layer):\n",
    "\n",
    "    def __init__(self, layers: List[Layer]) -> None:\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x) -> Any:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self) -> List[torch.tensor]:\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of elements: 76579\n"
     ]
    }
   ],
   "source": [
    "n_embd = 24  # the dimensionality of the character embedding vectors\n",
    "n_hidden = 128  # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)     # , bias=True),\n",
    "    # NOTE: the bias if False for the first linear layer as it is followed by the batchnorm layer and it is False for the last layer as it is not followed by the batchnorm layer.\n",
    "])\n",
    "\n",
    "# NOTE: there are similar results when placing batchnorm after activation layers\n",
    "\n",
    "with torch.no_grad():\n",
    "    # last layer: make less confident\n",
    "    model.layers[-1].weights *= 0.1\n",
    "\n",
    "\n",
    "# parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "# parameters = [p for layer in layers for p in layer.parameters()]\n",
    "parameters = model.parameters()\n",
    "\n",
    "print(f\"Total num of elements: {sum(p.nelement() for p in parameters)}\")\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: We are crushing too much information for our basic network (data compression during learning) by simply scaling the dataset or vocab size to 8\n",
    "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "model(Xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (32, 8, 24)\n",
      "FlattenConsecutive : (32, 4, 48)\n",
      "Linear : (32, 4, 128)\n",
      "BatchNorm1d : (32, 4, 128)\n",
      "Tanh : (32, 4, 128)\n",
      "FlattenConsecutive : (32, 2, 256)\n",
      "Linear : (32, 2, 128)\n",
      "BatchNorm1d : (32, 2, 128)\n",
      "Tanh : (32, 2, 128)\n",
      "FlattenConsecutive : (32, 256)\n",
      "Linear : (32, 128)\n",
      "BatchNorm1d : (32, 128)\n",
      "Tanh : (32, 128)\n",
      "Linear : (32, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(f\"{layer.__class__.__name__} : {tuple(layer.out.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3111\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xbatch, Ybatch = Xtr[ix], Ytr[ix]\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(Xbatch)\n",
    "    loss = F.cross_entropy(logits, target=Ybatch)\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # parameter update\n",
    "    lr = 0.1 if i < 150000 else 0.01\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"{i:7d}/{n_epochs:7d}: {loss.item():.4f}\")\n",
    "\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance log\n",
    "\n",
    "Write down every new feature you did or bug you fixed: the new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1000]' is invalid for input of size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlossi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m));\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1000]' is invalid for input of size 1"
     ]
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode (especially needed for batchnorm specifically)\n",
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 3.8625447750091553\n",
      "val 3.867837429046631\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def split_loss(split: str):\n",
    "    x, y = {\n",
    "        \"train\": (Xtr, Ytr),\n",
    "        \"val\": (Xdev, Ydev),\n",
    "        \"test\": (Xte, Yte)\n",
    "    }[split]\n",
    "\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss(\"train\")\n",
    "split_loss(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aelxptlp.\n",
      "tblqxnymscljnnnalxibt.\n",
      "pmgknnyackttelvjwuqpdarjgfvmkydreqpulpfncqvesolvmrnzwjsftsocspzaksyeckujnq.\n",
      "olpppulturx.\n",
      "encxpswgvgugyyyizveqdkjutdhrzm.\n",
      "fyfnmuufhrmlvespegbsblwzj.\n",
      "esoqsyqfeod.\n",
      "lxgkifglvghvetpbnf.\n",
      "hxdundjgzdefop.\n",
      "m.\n",
      "fzriufjehsniflsuddnfj.\n",
      "klrtcobzgxpnltorawlvxnm.\n",
      "eeppdmyynkoblqegh.\n",
      "awcqxnyou.\n",
      "mm.\n",
      "ayvclvtuidmcujpdnyn.\n",
      "mmhrybioutgrrawsoloppbxkyfzlcunynhtdbs.\n",
      "g.\n",
      "darwqw.\n",
      "xej.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "\n",
    "    while True:\n",
    "        logits = model(torch.tensor([context]))\n",
    "\n",
    "        # NOTE you were getting nan probs as you didnt set the layers to inference/eval mode\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        # shift the context window and track the samples\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(\"\".join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem with NaNs and infs\n",
    "\n",
    "The problem was with the batchnorm layer being still in training mode as it is trying to calculate the variance/spread of a single unit (when we are doing inference) and a variance of a single number is not a number as we can see below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_292929/1630907252.py:1: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1807.)\n",
      "  torch.var(torch.tensor([5.0]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(torch.tensor  ([5.0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
